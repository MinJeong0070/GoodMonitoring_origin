# main_script.py

import os
import re
import time
import pandas as pd
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed

from dotenv import load_dotenv

from src.core_utils import (
    create_driver, kill_driver, clean_text,
    extract_first_sentences, generate_search_queries,
    calculate_copy_ratio, log, search_news_with_api, similar_sentence
)

today = datetime.now().strftime("%y%m%d")
input_path = f"../../ì „ì²˜ë¦¬/6ì›”/ë½ë¿Œ_ì „ì²˜ë¦¬_250704.xlsx"
output_path = f"../../ê²°ê³¼/ë½ë¿Œ_ì›ë¬¸ê¸°ì‚¬_6ì›”_{today}.csv"
os.makedirs(f"../../ê²°ê³¼/ê¸°ì‚¬ë³¸ë¬¸_{today}", exist_ok=True)

def find_original_article_multiprocess(index, row_dict, total_count):
    # api í‚¤ ì„¤ì •
    load_dotenv(dotenv_path="../../.gitignore/ë„¤ì´ë²„APIí‚¤_2.env")

    # í‚¤ ì½ê¸°
    client_id = os.getenv("NAVER_CLIENT_ID")
    client_secret = os.getenv("NAVER_CLIENT_SECRET")

    driver = create_driver(index)
    if index == 0:
        time.sleep(10)  # ì²« íƒœìŠ¤í¬ë§Œ ì ì‹œ ëŒ€ê¸°
    if driver is None:
        log("âŒ ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨ â†’ ìŠ¤í‚µ", index)
        return index, "", 0.0

    driver_quit_needed = True

    try:
        title = clean_text(str(row_dict["ê²Œì‹œë¬¼ ì œëª©"]))
        content = clean_text(str(row_dict["ê²Œì‹œë¬¼ ë‚´ìš©"]))
        press = clean_text(str(row_dict["ê²€ìƒ‰ì–´"]))
        # #í‹°ìŠ¤í† ë¦¬
        # title = clean_text(str(row_dict["ê²Œì‹œê¸€ ì œëª©"]))
        # content = clean_text(str(row_dict["ê²Œì‹œê¸€ë‚´ìš©"]))
        # press = clean_text(str(row_dict["ê²€ìƒ‰ì–´"]))

        first, second, last = extract_first_sentences(content)
        queries = generate_search_queries(title, first, second,last, press)
        log(f"ğŸ” ê²€ìƒ‰ì–´: {queries}", index)

        search_results = search_news_with_api(queries, driver, client_id, client_secret, index=index)
        if not search_results:
            log("âŒ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ", index)
            return index, "", 0.0

        best = max(search_results, key=lambda x: calculate_copy_ratio(x["body"], title + " " + content))
        score = calculate_copy_ratio(best["body"], title + " " + content)

        # if not similar_sentence(best["body"], title + " " + content):
        #     log("âš ï¸ ìœ ì‚¬ ë¬¸ì¥ ì—†ìŒ", index)
        #     return index, "", 0.0

        if score >= 0.0:
            filename = f"../../ê²°ê³¼/ê¸°ì‚¬ë³¸ë¬¸_{today}/{index+1:03d}_{re.sub(r'[\\/*?:\"<>|]', '', title)[:50]}.txt"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(f"[URL] {best['link']}\n\n{best['body']}")
            log(f"ğŸ“ ì €ì¥ ì™„ë£Œ â†’ {filename} (ë³µì‚¬ìœ¨: {score})", index)

            # â¬‡ ì—‘ì…€ì— í•˜ì´í¼ë§í¬ í¬ë§·ìœ¼ë¡œ ì €ì¥
            hyperlink = f'=HYPERLINK("{best["link"]}")'
            return index, hyperlink, score
        else:
            log(f"âš ï¸ ë³µì‚¬ìœ¨ ë‚®ìŒ (ë³µì‚¬ìœ¨: {score})", index)
            return index, "", 0.0  # ë³µì‚¬ìœ¨ ë‚®ìœ¼ë©´ ì•„ë¬´ê²ƒë„ ì €ì¥ ì•ˆ í•¨

    except Exception as e:
        log(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}", index)
        return index, "", 0.0
    finally:
        if driver_quit_needed:
            kill_driver(driver, index)


if __name__ == "__main__":
    df = pd.read_excel(input_path, dtype={"ê²Œì‹œê¸€ ë“±ë¡ì¼ì": str})
    total = len(df)
    log(f"ğŸ“„ ì „ì²´ ê²Œì‹œê¸€ ìˆ˜: {total}ê°œ")
    if "ê²Œì‹œë¬¼ URL" in df.columns:
        df["ê²Œì‹œë¬¼ URL"] = df["ê²Œì‹œë¬¼ URL"].apply(
            lambda x: f'=HYPERLINK("{x}")' if pd.notna(x) and not str(x).startswith("=HYPERLINK") else x
        )
    df["ì›ë³¸ê¸°ì‚¬"] = ""
    df["ë³µì‚¬ìœ¨"] = 0.0
    total = len(df)
    start_index = 0
    tasks = [(start_index+ i, row.to_dict(), total) for i, row in df.iterrows()]

    with ProcessPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(find_original_article_multiprocess, *args) for args in tasks]
        for future in as_completed(futures):
            try:
                index, link, score = future.result()
                df.at[index, "ì›ë³¸ê¸°ì‚¬"] = link
                df.at[index, "ë³µì‚¬ìœ¨"] = score
            except Exception as e:
                log(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    # ë§¤ì¹­ í†µê³„ ê³„ì‚°
    matched_count = df["ë³µì‚¬ìœ¨"].gt(0).sum()  # ë³µì‚¬ìœ¨ > 0
    above_80_count = df["ë³µì‚¬ìœ¨"].ge(0.8).sum()  # ë³µì‚¬ìœ¨ â‰¥ 0.8
    above_30_count = df["ë³µì‚¬ìœ¨"].ge(0.3).sum() - above_80_count  # 0.3 ì´ìƒ ì¤‘ 0.8 ë¯¸ë§Œ

    # í†µê³„ í–‰ êµ¬ì„±
    stats_rows = pd.DataFrame([
        {"ê²€ìƒ‰ì–´": "ë§¤ì¹­ê±´ìˆ˜", "í”Œë«í¼": f"{matched_count}ê±´"},
        {"ê²€ìƒ‰ì–´": "0.3 ì´ìƒ", "í”Œë«í¼": f"{above_30_count}ê±´"},
        {"ê²€ìƒ‰ì–´": "0.8 ì´ìƒ", "í”Œë«í¼": f"{above_80_count}ê±´"},
    ])

    # ê¸°ì¡´ dfì— í–‰ ì¶”ê°€
    df = pd.concat([df, stats_rows], ignore_index=True)

    # ì €ì¥
    df.to_csv(output_path, index=False)
    log("ğŸ“Š í†µê³„ ìš”ì•½")
    log(f" ë§¤ì¹­ê±´ìˆ˜: {matched_count}ê±´")
    log(f" 0.3 ì´ìƒ: {above_30_count}ê±´")
    log(f" 0.8 ì´ìƒ: {above_80_count}ê±´")
    log(f"ğŸ‰ ì™„ë£Œ! ì €ì¥ë¨ â†’ {output_path}")
