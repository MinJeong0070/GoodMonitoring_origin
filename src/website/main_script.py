# main_script.py
import os
import re
import time
import pandas as pd
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed

from dotenv import load_dotenv

from src.core_utils import (
    clean_text,
    exact_copy_rate,
    create_driver,
    kill_driver,
    log,
    extract_first_sentences,
    generate_search_queries,
    search_news_with_api,
)

today = datetime.now().strftime("%y%m%d")
input_path = f"../../ì „ì²˜ë¦¬/ë””ì‹œì¸ì‚¬ì´ë“œ_ì „ì²˜ë¦¬_250911.xlsx"
output_path = f"../../ê²°ê³¼/ë””ì‹œì¸ì‚¬ì´ë“œ í…ŒìŠ¤íŠ¸_9ì›”_{today}.csv"
os.makedirs(f"../../ê²°ê³¼/ê¸°ì‚¬ë³¸ë¬¸_{today}", exist_ok=True)

def find_original_article_multiprocess(index, row_dict, total_count):
    from dotenv import load_dotenv
    # api í‚¤ ì„¤ì •
    load_dotenv(dotenv_path="../../.gitignore/.env")

    # í‚¤ ì½ê¸°
    client_id = os.getenv("NAVER_CLIENT_ID")
    client_secret = os.getenv("NAVER_CLIENT_SECRET")

    driver = create_driver(index)
    if index == 0:
        time.sleep(10)  # ì²« íƒœìŠ¤í¬ë§Œ ì ì‹œ ëŒ€ê¸°
    if driver is None:
        log("âŒ ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨ â†’ ìŠ¤í‚µ", index)
        return index, "", 0.0

    driver_quit_needed = True

    try:
        title = clean_text(str(row_dict["ê²Œì‹œë¬¼ ì œëª©"]))
        content = clean_text(str(row_dict["ê²Œì‹œë¬¼ ë‚´ìš©"]))

        first, second, last = extract_first_sentences(content)
        queries = generate_search_queries(title, first, second, last)
        log(f"ğŸ” ê²€ìƒ‰ì–´: {queries}", index)

        search_results = search_news_with_api(queries, driver, client_id, client_secret, index=index)
        if not search_results:
            log("âŒ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ", index)
            return index, "", 0.0

        # âœ… ê¸°ì¡´ calculate_copy_ratio â†’ exact_copy_rate ë¡œ êµì²´
        best = max(
            search_results,
            key=lambda x: exact_copy_rate(x["body"], title + " " + content, mode="sentence", min_chars=20, min_tokens=5)
        )
        score = exact_copy_rate(
            best["body"],
            f"{title} {content}",
            mode="hybrid",  # ë¬¸ì¥ ì¼ì¹˜ + ê±°ì˜-ì¼ì¹˜ + substr ë³´ì •
            min_chars=20,
            min_tokens=5,
            almost_tol=0.98
        )

        if score > 0.0:
            safe_title = re.sub(r'[/*?:<>|]', '', title)[:50]  # ì „ì—­ import re í™œìš©
            filename = f"../../ê²°ê³¼/ê¸°ì‚¬ë³¸ë¬¸_{today}/{index + 1:03d}_{safe_title}.txt"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(f"[URL] {best['link']}\n\n{best['body']}")
            log(f"ğŸ“ ì €ì¥ ì™„ë£Œ â†’ {filename} (ë³µì œìœ¨: {score})", index)

            hyperlink = f'=HYPERLINK("{best["link"]}")'
            return index, hyperlink, score
        else:
            log(f"âš ï¸ ë³µì œìœ¨ ë‚®ìŒ (ë³µì œìœ¨: {score})", index)
            return index, "", 0.0

    except Exception as e:
        log(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}", index)
        return index, "", 0.0
    finally:
        if driver_quit_needed:
            kill_driver(driver, index)

if __name__ == "__main__":
    df = pd.read_excel(input_path, dtype={"ê²Œì‹œê¸€ ë“±ë¡ì¼ì": str})
    total = len(df)
    log(f"ğŸ“„ ì „ì²´ ê²Œì‹œê¸€ ìˆ˜: {total}ê°œ")
    if "ê²Œì‹œë¬¼ URL" in df.columns:
        df["ê²Œì‹œë¬¼ URL"] = df["ê²Œì‹œë¬¼ URL"].apply(
            lambda x: f'=HYPERLINK("{x}")' if pd.notna(x) and not str(x).startswith("=HYPERLINK") else x
        )
    df["ì›ë³¸ê¸°ì‚¬"] = ""
    df["ë³µì‚¬ìœ¨"] = 0.0
    total = len(df)
    start_index = 0
    tasks = [(start_index+ i, row.to_dict(), total) for i, row in df.iterrows()]

    with ProcessPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(find_original_article_multiprocess, *args) for args in tasks]
        for future in as_completed(futures):
            try:
                index, link, score = future.result()
                df.at[index, "ì›ë³¸ê¸°ì‚¬"] = link
                df.at[index, "ë³µì‚¬ìœ¨"] = score
            except Exception as e:
                log(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    # ë§¤ì¹­ í†µê³„ ê³„ì‚°
    matched_count = df["ë³µì‚¬ìœ¨"].gt(0).sum()  # ë³µì‚¬ìœ¨ > 0
    above_90_count = df["ë³µì‚¬ìœ¨"].ge(0.9).sum()  # ë³µì‚¬ìœ¨ â‰¥ 0.9
    above_50_count = df["ë³µì‚¬ìœ¨"].ge(0.5).sum() - above_90_count  # 0.3 ì´ìƒ ì¤‘ 0.8 ë¯¸ë§Œ

    # í†µê³„ í–‰ êµ¬ì„±
    stats_rows = pd.DataFrame([
        {"ê²€ìƒ‰ì–´": "ë§¤ì¹­ê±´ìˆ˜", "í”Œë«í¼": f"{matched_count}ê±´"},
        {"ê²€ìƒ‰ì–´": "0.5 ì´ìƒ", "í”Œë«í¼": f"{above_50_count}ê±´"},
        {"ê²€ìƒ‰ì–´": "0.9 ì´ìƒ", "í”Œë«í¼": f"{above_90_count}ê±´"},
    ])

    # ê¸°ì¡´ dfì— í–‰ ì¶”ê°€
    df = pd.concat([df, stats_rows], ignore_index=True)

    # ì €ì¥
    df.to_csv(output_path, index=False)
    log("ğŸ“Š í†µê³„ ìš”ì•½")
    log(f" ë§¤ì¹­ê±´ìˆ˜: {matched_count}ê±´")
    log(f" 0.5 ì´ìƒ: {above_50_count}ê±´")
    log(f" 0.9 ì´ìƒ: {above_90_count}ê±´")
    log(f"ğŸ‰ ì™„ë£Œ! ì €ì¥ë¨ â†’ {output_path}")
