import os
import re
import pandas as pd
from datetime import datetime

from src.core_utils import clean_text, calculate_copy_ratio, log

# ë‚ ì§œ
today = datetime.now().strftime("%y%m%d")

# ê²½ë¡œ ì„¤ì •
input_path = f"../../ì „ì²˜ë¦¬/5ì›”/ì›ƒê¸´ëŒ€í•™_ì „ì²˜ë¦¬_5ì›”_250604.xlsx"
article_folder = f"../../ê²°ê³¼/5ì›” ì›ë¬¸ê¸°ì‚¬ìžë£Œ/ê¸°ì‚¬ë³¸ë¬¸_ì›ƒê¸´ëŒ€í•™5ì›”_250611"
output_path = f"../../ê²°ê³¼/ì›ë¬¸ê¸°ì‚¬_ì›ƒê¸´ëŒ€í•™_{today}.csv"

# ì—‘ì…€ ë¡œë“œ
df = pd.read_excel(input_path, dtype={"ê²Œì‹œê¸€ ë“±ë¡ì¼ìž": str})
log(f"ðŸ“‚ ì—‘ì…€ ë¡œë“œ ì™„ë£Œ â†’ {input_path}")

# ê²Œì‹œë¬¼ URL í•˜ì´í¼ë§í¬ ì ìš©
if "ê²Œì‹œë¬¼ URL" in df.columns:
    df["ê²Œì‹œë¬¼ URL"] = df["ê²Œì‹œë¬¼ URL"].apply(
        lambda x: f'=HYPERLINK("{x}")' if pd.notna(x) and not str(x).startswith("=HYPERLINK") else x
    )

# ë³µì‚¬ìœ¨ ë° ì›ë³¸ê¸°ì‚¬ ì—´ì´ ì—†ìœ¼ë©´ ìƒì„±
if "ì›ë³¸ê¸°ì‚¬" not in df.columns:
    df["ì›ë³¸ê¸°ì‚¬"] = ""
if "ë³µì‚¬ìœ¨" not in df.columns:
    df["ë³µì‚¬ìœ¨"] = 0.0

# ê¸°ì‚¬ë³¸ë¬¸ í…ìŠ¤íŠ¸ íŒŒì¼ ëª©ë¡
if not os.path.exists(article_folder):
    log(f"ðŸš« ê¸°ì‚¬ë³¸ë¬¸ í´ë”ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {article_folder}")
    exit()

files = [f for f in os.listdir(article_folder) if f.endswith(".txt")]
log(f"ðŸ“° ê¸°ì‚¬ë³¸ë¬¸ íŒŒì¼ {len(files)}ê°œ í™•ì¸ë¨")

# ê¸°ì‚¬ë³¸ë¬¸ íŒŒì¼ ê¸°ë°˜ ë³µì‚¬ìœ¨ ìž¬ê³„ì‚°
for filename in files:
    try:
        index_str = filename.split("_")[0]
        if not index_str.isdigit():
            continue
        index = int(index_str) - 1  # íŒŒì¼ ë²ˆí˜¸ëŠ” 1ë¶€í„° ì‹œìž‘, df indexëŠ” 0ë¶€í„°

        if index >= len(df):
            continue

        title = clean_text(str(df.at[index, "ê²Œì‹œë¬¼ ì œëª©"]))
        content = clean_text(str(df.at[index, "ê²Œì‹œë¬¼ ë‚´ìš©"]))

        filepath = os.path.join(article_folder, filename)
        with open(filepath, "r", encoding="utf-8") as f:
            lines = f.readlines()

        if not lines:
            continue

        url_match = re.search(r'\[URL\]\s*(\S+)', lines[0])
        if not url_match:
            continue

        url = url_match.group(1)
        body = "".join(lines[2:]).strip()
        if not body or len(body) < 100:
            continue

        score = calculate_copy_ratio(body, title + " " + content)
        hyperlink = f'=HYPERLINK("{url}")'

        df.at[index, "ì›ë³¸ê¸°ì‚¬"] = hyperlink
        df.at[index, "ë³µì‚¬ìœ¨"] = round(score, 3)

        log(f"âœ… ë³µêµ¬ ì™„ë£Œ [{index+1:03d}] â†’ ë³µì‚¬ìœ¨: {score}")

    except Exception as e:
        log(f"âŒ ë³µêµ¬ ì‹¤íŒ¨ [{filename}] â†’ {e}")

# ðŸ“Š ë³µì‚¬ìœ¨ í†µê³„ ê³„ì‚°
matched_count = df["ë³µì‚¬ìœ¨"].gt(0).sum()
above_80_count = df["ë³µì‚¬ìœ¨"].ge(0.8).sum()
above_30_count = df[(df["ë³µì‚¬ìœ¨"] >= 0.3) & (df["ë³µì‚¬ìœ¨"] < 0.8)].shape[0]

log("ðŸ“Š ë³µì‚¬ìœ¨ í†µê³„ ìš”ì•½")
log(f" ë§¤ì¹­ê±´ìˆ˜: {matched_count}ê±´")
log(f" 0.3 ì´ìƒ: {above_30_count}ê±´")
log(f" 0.8 ì´ìƒ: {above_80_count}ê±´")

# í†µê³„ í–‰ì„ ë°ì´í„°í”„ë ˆìž„ ëì— ì¶”ê°€
stats_rows = pd.DataFrame([
    {"ê²€ìƒ‰ì–´": "ë§¤ì¹­ê±´ìˆ˜", "í”Œëž«í¼": f"{matched_count}ê±´"},
    {"ê²€ìƒ‰ì–´": "0.3 ì´ìƒ", "í”Œëž«í¼": f"{above_30_count}ê±´"},
    {"ê²€ìƒ‰ì–´": "0.8 ì´ìƒ", "í”Œëž«í¼": f"{above_80_count}ê±´"},
])

df = pd.concat([df, stats_rows], ignore_index=True)

# ðŸ’¾ ì €ìž¥
df.to_csv(output_path, index=False)
log(f"ðŸ’¾ ë³µêµ¬ëœ ì—‘ì…€ ì €ìž¥ ì™„ë£Œ â†’ {output_path}")
